{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FlyingSquid for Video\n",
    "\n",
    "In this notebook, we'll use FlyingSquid to train a label model for sequential video data. In this application, we'll be using broadcast tennis footage to detect tennis rallies (when the two players are continuously hitting the ball back and forth).\n",
    "\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr style=\"background:none\">\n",
    "        <th><img src=\"https://raw.githubusercontent.com/HazyResearch/flyingsquid/master/figs/tennis_rally.png\" width=\"100%\"></th>\n",
    "        <th><img src=\"https://raw.githubusercontent.com/HazyResearch/flyingsquid/master/figs/tennis_nonrally.png\" width=\"100%\"></th>\n",
    "    </tr>\n",
    "    <tr style=\"font-weight: bold; font-size:large; background:none\">\n",
    "        <td style=\"text-align: center\">Rally Segment</td>\n",
    "        <td style=\"text-align: center\">Non-Rally Segment</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Labeling Function Outputs\n",
    "Again, we'll start by loading labeling function outputs. This time, we'll load in the outputs from actual labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6959, 6)\n",
      "(746, 6)\n",
      "(746,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tutorial_helpers import *\n",
    "\n",
    "L_train = np.load('L_train_video.npy')\n",
    "L_dev = np.load('L_dev_video.npy')\n",
    "Y_dev = np.load('Y_dev_video.npy')\n",
    "\n",
    "print(L_train.shape)\n",
    "print(L_dev.shape)\n",
    "print(Y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our L and Y matrices, each row represents a single frame in the video. Since rallies occur over contiguous frames, notice that the ground truth annotations have contiguous segments of the same label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dev[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These labeling functions were written using [Rekall queries](https://github.com/scanner-research/rekall) and express heuristics like the number of people on court, the size of the people, and the number of near-white pixels. Notice that abstain rates tend to be much lower when using Rekall queries, since many queries automatically label the whole video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF 0: Accuracy 87%, Abstain rate 0%\n",
      "LF 1: Accuracy 89%, Abstain rate 0%\n",
      "LF 2: Accuracy 57%, Abstain rate 85%\n",
      "LF 3: Accuracy 84%, Abstain rate 39%\n",
      "LF 4: Accuracy 86%, Abstain rate 0%\n",
      "LF 5: Accuracy 62%, Abstain rate 60%\n"
     ]
    }
   ],
   "source": [
    "print_statistics(L_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model the labeling functions (and temporal dependencies) with FlyingSquid\n",
    "\n",
    "Next, we're going to use FlyingSquid to model the labeling functions. But we're going to end up doing something slightly more complicated in order to model temporal dependencies.\n",
    "\n",
    "We'll model three frames at a time with three hidden variables, and model each labeling function labeling an individual frame in the sequence:\n",
    "\n",
    "<div>\n",
    "  <img src=\"https://raw.githubusercontent.com/HazyResearch/flyingsquid/master/figs/graphical_structure_video.png\" style=\"padding: 20px 30px\" width = '800px'>\n",
    "</div>\n",
    "\n",
    "In a given sequence of three frames, `lambda_0`, `lambda_6`, and `lambda_12` model LF 0's outputs on the first, second, and third frames, respectively. Similarly, `lambda_1`, `lambda_7`, and `lambda_13` model LF 1's outputs on the first, second, and third frames.\n",
    "\n",
    "Our first step is resizing and reshaping our matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use v to denote the length of sequence we're modeling\n",
    "v = 3\n",
    "\n",
    "# Six labeling functions per frame\n",
    "m_per_frame = 6\n",
    "\n",
    "# Total number of labeling functions is m_per_frame * v\n",
    "m = m_per_frame * v\n",
    "\n",
    "# Figure out how many sequences we're going to have\n",
    "n_frames_train = L_train.shape[0]\n",
    "n_frames_dev = L_dev.shape[0]\n",
    "\n",
    "n_seqs_train = n_frames_train // v\n",
    "n_seqs_dev = n_frames_dev // v\n",
    "\n",
    "# Resize and reshape matrices\n",
    "L_train_seqs = L_train[:n_seqs_train * v].reshape((n_seqs_train, m))\n",
    "L_dev_seqs = L_dev[:n_seqs_dev * v].reshape((n_seqs_dev, m))\n",
    "Y_dev_seqs = Y_dev[:n_seqs_dev * v].reshape((n_seqs_dev, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use FlyingSquid to model this dependency structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flyingsquid.label_model import LabelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model = LabelModel(\n",
    "    m,\n",
    "    v = v,\n",
    "    y_edges = [\n",
    "        (0, 1), (1, 2)\n",
    "    ],\n",
    "    lambda_y_edges = [\n",
    "        (0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0),\n",
    "        (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1),\n",
    "        (12, 2), (13, 2), (14, 2), (15, 2), (16, 2), (17, 2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain each argument that we just passed to `LabelModel`:\n",
    "* Our first argument is still `m`, the total number of labeling functions.\n",
    "* The second argument, `v`, specifies how many sequences we're modeling.\n",
    "* The third argument, `y_edges`, specifies (non-directional) edges between the hidden variables. Each pair in the array specifies an edge; in this case, we are specifying edges between `Y_0` and `Y_1`, and between `Y_1` and `Y_2`.\n",
    "* The fourth argument, `lambda_y_edges`, specifies (non-directional) edges between observable variables and hidden variables. In this case, each pair in the array specifies an edge by using the first item to index into the observable varialbes, and using the second item to index into the hidden variables.\n",
    "\n",
    "Now that we understand what's going on, we can actually express this in fewer lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simpler way to build the label model\n",
    "label_model = LabelModel(\n",
    "    m,\n",
    "    v = v,\n",
    "    y_edges = [ (i, i + 1) for i in range(v - 1) ],\n",
    "    lambda_y_edges = [ (i, i // m_per_frame) for i in range(m) ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will work for most video tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the label model, all we need to do is pass `L_train_seqs` to the fit function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model.fit(L_train_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the label model\n",
    "\n",
    "Now, let's use the dev set to evaluate the label model.\n",
    "\n",
    "Since we are now modeling sequences, we want to use the function `predict_proba_marginalized` to get predictions for individual frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label model accuracy: 88%\n"
     ]
    }
   ],
   "source": [
    "probabilistic_labels = label_model.predict_proba_marginalized(L_dev_seqs)\n",
    "preds = [ 1. if prob > 0.5 else -1. for prob in probabilistic_labels ]\n",
    "accuracy = np.sum(preds == Y_dev[:n_seqs_dev * v]) / (n_seqs_dev * v)\n",
    "\n",
    "print('Label model accuracy: {}%'.format(int(100 * accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see that this performs much better than majority vote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority vote accuracy: 33%\n"
     ]
    }
   ],
   "source": [
    "majority_vote_preds = np.sum(L_dev, axis=1) > 0\n",
    "majority_vote_accuracy = np.sum(majority_vote_preds == Y_dev) / Y_dev.shape[0]\n",
    "\n",
    "print('Majority vote accuracy: {}%'.format(int(100 * majority_vote_accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training an End Model\n",
    "If necessary, we can use the probabilistic labels to train up an end model. All we need to do is call `predict_proba_marginalized` over `L_train_seqs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6957,)\n",
      "[9.95970565e-01 9.45002920e-01 9.61349604e-01 9.95970565e-01\n",
      " 9.45002920e-01 9.98849719e-01 9.99250640e-01 9.98525418e-01\n",
      " 9.96477675e-01 9.99953165e-01 9.99213851e-01 7.91527313e-01\n",
      " 9.99991330e-01 9.82809821e-01 9.98691913e-01 9.99944174e-01\n",
      " 9.98525418e-01 9.99930068e-01 9.99998119e-01 9.99658311e-01\n",
      " 9.99930068e-01 9.99998119e-01 9.99658311e-01 9.99930068e-01\n",
      " 9.99998119e-01 9.99658311e-01 9.23526306e-01 1.15346375e-03\n",
      " 1.28974667e-03 2.06006806e-04 1.15346375e-03 1.74129763e-03\n",
      " 2.34298998e-04 1.15346375e-03 8.54307705e-03 7.48697405e-03\n",
      " 5.71032053e-03 8.54307705e-03 7.48697405e-03 9.99250640e-01\n",
      " 9.98525418e-01 2.18199807e-01 9.99991330e-01 9.87216252e-01\n",
      " 9.96477675e-01 9.99991330e-01 9.98525418e-01 9.95995757e-01\n",
      " 9.99106918e-01 9.82809821e-01 9.98691913e-01 9.99944174e-01\n",
      " 6.33889805e-03 6.58867471e-03 4.79508961e-03 9.86709989e-01\n",
      " 9.96477675e-01 9.99992726e-01 9.99213851e-01 9.98849719e-01\n",
      " 9.99250640e-01 1.74129763e-03 2.34298998e-04 1.15346375e-03\n",
      " 1.74129763e-03 2.34298998e-04 1.15346375e-03 9.98938427e-01\n",
      " 9.13925457e-01 9.99953165e-01 9.82809821e-01 9.96477675e-01\n",
      " 9.99992726e-01 9.99213851e-01 9.98849719e-01 9.99992726e-01\n",
      " 9.98009283e-01 9.96477675e-01 9.99106918e-01 9.98938427e-01\n",
      " 9.95995757e-01 9.99944174e-01 9.98009283e-01 2.33811138e-03\n",
      " 9.67879509e-04 1.28974667e-03 2.34298998e-04 1.15346375e-03\n",
      " 1.74129763e-03 2.34298998e-04 1.15346375e-03 1.74129763e-03\n",
      " 9.23526306e-01 9.99250640e-01 9.99213851e-01 9.98849719e-01\n",
      " 9.99992726e-01 9.99213851e-01 6.67422449e-01 3.18205893e-01]\n"
     ]
    }
   ],
   "source": [
    "probabilistic_labels = label_model.predict_proba_marginalized(L_train_seqs)\n",
    "print(probabilistic_labels.shape)\n",
    "print(probabilistic_labels[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Dependencies between labeling functions\n",
    "\n",
    "Now that we know how to specify dependencies manually, it's a simple step to specify dependencies between labeling functions:\n",
    "\n",
    "<div>\n",
    "  <img src=\"https://raw.githubusercontent.com/HazyResearch/flyingsquid/master/figs/graphical_structure_video_lambda_dep.png\" style=\"padding: 20px 30px\" width = '800px'>\n",
    "</div>\n",
    "\n",
    "All you have to do is pass in an extra argument, `lambda_edges`, that specifies edges between observable variables. For example, you can specify the above graph like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Label model with dependencies between lambda_0 and lambda_1\n",
    "label_model = LabelModel(\n",
    "    m,\n",
    "    v = v,\n",
    "    y_edges = [ (i, i + 1) for i in range(v - 1) ],\n",
    "    lambda_y_edges = [ (i, i // m_per_frame) for i in range(m) ],\n",
    "    lambda_edges = [ (0, 1) ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:flyingsquid] *",
   "language": "python",
   "name": "conda-env-flyingsquid-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
